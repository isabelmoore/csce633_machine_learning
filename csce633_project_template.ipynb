{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabelmoore/csce633_machine_learning/blob/main/csce633_project_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Language-Image Pretraining with SogCLR"
      ],
      "metadata": {
        "id": "cwwBXvIbUXA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introduction**\n",
        "\n",
        "In this tutorial, you will learn how to conduct contrastive language-image pretraining by optimizing the [Global Contrastive Loss](https://arxiv.org/abs/2202.12387) (GCL) on a subset of the [Conceptual Captions](https://ai.google.com/research/ConceptualCaptions/) dataset. Also, you will learn how to evaluate the model on retrieval task using the [MSCOCO](https://cocodataset.org/#home) dataset and zero-shot classification task using the [ImageNet](https://www.image-net.org/challenges/LSVRC/index.php) dataset. The code is based on [iSogCLR's](https://github.com/zhqiu/contrastive-learning-iSogCLR) codebase, which includes the implementation of CLIP, SogCLR and iSogCLR."
      ],
      "metadata": {
        "id": "kVyLXcCiUkeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation\n",
        "\n",
        "First, we:\n",
        "\n",
        "1. Download the source code and data\n",
        "2. Install required packages"
      ],
      "metadata": {
        "id": "DsO954DCVdgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3wc5FDn51l6",
        "outputId": "857fc308-6bfe-465f-b3f6-66580362319e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iSogCLR'...\n",
            "remote: Enumerating objects: 314, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 314 (delta 17), reused 13 (delta 13), pack-reused 289 (from 2)\u001b[K\n",
            "Receiving objects: 100% (314/314), 152.51 KiB | 21.79 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=142xxRoMaHxX3BIfCw_1b_G_dgu-02Yq3\n",
            "To: /content/clip_train.tar.gz\n",
            "100% 4.06M/4.06M [00:00<00:00, 250MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT\n",
            "From (redirected): https://drive.google.com/uc?id=142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT&confirm=t&uuid=5731e7b2-ecc7-460a-8bbf-fdab8ae8e21b\n",
            "To: /content/cc3m_subset_100k.tar.gz\n",
            "100% 3.07G/3.07G [00:37<00:00, 81.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=142tMsnclHTTPpnTXHSeNgTUlBk4She6o\n",
            "From (redirected): https://drive.google.com/uc?id=142tMsnclHTTPpnTXHSeNgTUlBk4She6o&confirm=t&uuid=afae8307-7dba-4d8b-8862-e2e84bdb0aba\n",
            "To: /content/mscoco_val.tar.gz\n",
            "100% 819M/819M [00:11<00:00, 73.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1NXhfhwFy-nhdABACkodgYqm9pomDKE39\n",
            "From (redirected): https://drive.google.com/uc?id=1NXhfhwFy-nhdABACkodgYqm9pomDKE39&confirm=t&uuid=d2cd2b8e-2c1c-47bc-a223-d2b1cd0a5c13\n",
            "To: /content/val.tar\n",
            "100% 6.75G/6.75G [01:39<00:00, 68.1MB/s]\n",
            "Collecting braceexpand==0.1.7 (from -r ./iSogCLR/requirements_colab.txt (line 1))\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting colorama==0.4.6 (from -r ./iSogCLR/requirements_colab.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ftfy==6.1.1 (from -r ./iSogCLR/requirements_colab.txt (line 3))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting huggingface-hub==0.16.4 (from -r ./iSogCLR/requirements_colab.txt (line 4))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting safetensors==0.3.3 (from -r ./iSogCLR/requirements_colab.txt (line 5))\n",
            "  Downloading safetensors-0.3.3.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.7 (from -r ./iSogCLR/requirements_colab.txt (line 6))\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.14.0 (from -r ./iSogCLR/requirements_colab.txt (line 7))\n",
            "  Downloading tokenizers-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting transformers==4.34.0 (from -r ./iSogCLR/requirements_colab.txt (line 8))\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset==0.2.57 (from -r ./iSogCLR/requirements_colab.txt (line 9))\n",
            "  Downloading webdataset-0.2.57-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting accelerate==0.31.0 (from -r ./iSogCLR/requirements_colab.txt (line 10))\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting libauc==1.4.0 (from -r ./iSogCLR/requirements_colab.txt (line 11))\n",
            "  Downloading libauc-1.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from ftfy==6.1.1->-r ./iSogCLR/requirements_colab.txt (line 3)) (0.2.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.12/dist-packages (from timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (0.23.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r ./iSogCLR/requirements_colab.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.34.0->-r ./iSogCLR/requirements_colab.txt (line 8)) (2024.11.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.31.0->-r ./iSogCLR/requirements_colab.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (4.12.0.88)\n",
            "Collecting torch-geometric (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11))\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb (from libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2.5.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub==0.16.4->-r ./iSogCLR/requirements_colab.txt (line 4)) (2025.10.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (3.13.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (3.2.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (3.6.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric->libauc==1.4.0->-r ./iSogCLR/requirements_colab.txt (line 11)) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7->timm==0.9.7->-r ./iSogCLR/requirements_colab.txt (line 6)) (3.0.3)\n",
            "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m152.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.57-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libauc-1.4.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Building wheels for collected packages: safetensors\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for safetensors \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for safetensors (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for safetensors\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build safetensors\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (safetensors)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone -b project https://github.com/xywei00/csce689_iSogCLR.git iSogCLR\n",
        "\n",
        "!export PYTHONPATH=\"$PYTHONPATH:./iSogCLR/bimodal_exps\"\n",
        "!export HUGGINGFACE_HUB_CACHE='./checkpoints/huggingface'\n",
        "!mkdir checkpoints\n",
        "\n",
        "!gdown 142xxRoMaHxX3BIfCw_1b_G_dgu-02Yq3    # clip_train.tar.gz\n",
        "!gdown 142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT    # cc3m_subset_100k.tar.gz\n",
        "!gdown 142tMsnclHTTPpnTXHSeNgTUlBk4She6o    # ms_coco_val.tar.gz\n",
        "!gdown 1NXhfhwFy-nhdABACkodgYqm9pomDKE39    # val.tar\n",
        "\n",
        "!mkdir datasets\n",
        "!mkdir -p datasets/imagenet\n",
        "!tar xf clip_train.tar.gz\n",
        "!tar xf cc3m_subset_100k.tar.gz -C datasets\n",
        "!tar xf mscoco_val.tar.gz -C datasets\n",
        "!tar xf val.tar -C datasets/imagenet\n",
        "\n",
        "!pip install -r ./iSogCLR/requirements_colab.txt    # there may be pip warnings/ errors, should be fine to ignore them"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login\n",
        "!gcloud compute ssh instance-20251111-213126 --project=atomic-bird-475203-g6 --zone=us-central1-c --troubleshoot --tunnel-through-iap\n",
        "!gcloud compute ssh --zone \"us-central1-c\" \"instance-20251111-213126\" --project \"atomic-bird-475203-g6\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DdIwLU2vaww",
        "outputId": "3dec4b80-5758-421b-f537-8f43cc4ffa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=wHeD2OFXonMaAfiqkjjTP6qFq88SCB&prompt=consent&token_usage=remote&access_type=offline&code_challenge=COuZnhb7yOUuzrRT8c0kNvI3FhBwWsd_rHsQLy29SL8&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab32j90DhFAsDHTsh916Vt9nP1Wpi_oXCH4c2vp9VJd2I4vqU0i287gCxxBOsWX_XknkDA\n",
            "\n",
            "You are now logged in as [isabelmoore717@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\u001b[1;33mWARNING:\u001b[0m The private SSH key file for gcloud does not exist.\n",
            "\u001b[1;33mWARNING:\u001b[0m The public SSH key file for gcloud does not exist.\n",
            "\u001b[1;33mWARNING:\u001b[0m You do not have an SSH key for gcloud.\n",
            "\u001b[1;33mWARNING:\u001b[0m SSH keygen will be executed to generate a key.\n",
            "This tool needs to create the directory [/root/.ssh] before being able to \n",
            "generate SSH keys.\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "Generating public/private rsa key pair.\n",
            "Enter passphrase (empty for no passphrase): \n",
            "Enter same passphrase again: \n",
            "Your identification has been saved in /root/.ssh/google_compute_engine\n",
            "Your public key has been saved in /root/.ssh/google_compute_engine.pub\n",
            "The key fingerprint is:\n",
            "SHA256:CfAQW4kCFUupVY4DHugBKuzR6PuOBRLDT14yXzMBtf8 root@d60f33bbf350\n",
            "The key's randomart image is:\n",
            "+---[RSA 3072]----+\n",
            "|*+++=+++         |\n",
            "|*+B+.*. o        |\n",
            "|*O=*o.o=         |\n",
            "|=+=.= ..+.       |\n",
            "|.+ o .  S.       |\n",
            "|. o       .      |\n",
            "| . .       E     |\n",
            "|  +              |\n",
            "| ..o             |\n",
            "+----[SHA256]-----+\n",
            "\n",
            "Starting ssh troubleshooting for instance https://compute.googleapis.com/compute/v1/projects/atomic-bird-475203-g6/zones/us-central1-c/instances/instance-20251111-213126 in zone us-central1-c\n",
            "Start time: 2025-11-13 03:23:16.520385\n",
            "\n",
            "---- Checking network connectivity ----\n",
            "The Network Management API is needed to check the VM's network connectivity.\n",
            "\n",
            "If not already enabled, is it OK to enable it and check the VM's network \n",
            "connectivity? (Y/n)?  Y\n",
            "\n",
            "Your source IP address is 34.12.215.101\n",
            "\n",
            "Network Connectivity Test Result: REACHABLE\n",
            "\n",
            "To view complete details of this test, see https://console.cloud.google.com/net-intelligence/connectivity/tests/details/ssh-troubleshoot-rqe1b?project=atomic-bird-475203-g6\n",
            "\n",
            "Help for connectivity tests:\n",
            "https://cloud.google.com/network-intelligence-center/docs/connectivity-tests/concepts/overview\n",
            "\n",
            "---- Checking user permissions ----\n",
            "User permissions: 0 issue(s) found.\n",
            "\n",
            "---- Checking VPC settings ----\n",
            "VPC settings: 1 issue(s) found.\n",
            "\n",
            "There is an issue with your IAP configuration\n",
            "\n",
            "Check the following items:\n",
            " - The IAP firewall rule is valid.\n",
            " - IAP tunneling is enabled.\n",
            " - You are connecting using an IAP token.\n",
            " - You have the IAM role of Project Owner, IAP-Secured Tunnel User, or iap.tunnelInstances.accessViaIAP (preferred)\n",
            " - Your organization hasn't blocked access to external IP addresses. IAP changes the source traffic to 35.235.240.0/20 and the tunnel to https://tunnel.cloudproxy.app.\n",
            " - If your organization blocks access to public IP addresses, try connecting through a bastion server.\n",
            "\n",
            "Help for IAP port forwarding: https://cloud.google.com/iap/docs/using-tcp-forwarding\n",
            "https://cloud.google.com/iap/docs/faq#what_domain_does_for_tcp_use\n",
            "Help for bastion server: https://cloud.google.com/compute/docs/instances/connecting-advanced#bastion_host\n",
            "\n",
            "---- Checking VM status ----\n",
            "The Monitoring API is needed to check the VM's Status.\n",
            "\n",
            "If not already enabled, is it OK to enable it and check the VM's Status? (Y/n)?\n",
            "  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "project_root = '/content/drive/MyDrive/csce633/project'\n",
        "os.makedirs(project_root, exist_ok=True)\n",
        "%cd $project_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6zqI5EFi-yz",
        "outputId": "10ba9a03-22fa-4a4e-f21f-237e2903edef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/csce633/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if not os.path.exists(\"iSogCLR\"):\n",
        "    !git clone -b project https://github.com/xywei00/csce689_iSogCLR.git iSogCLR\n",
        "\n",
        "if not os.path.exists(\"checkpoints\"):\n",
        "    !mkdir -p checkpoints\n",
        "\n",
        "if not os.path.exists(\"datasets/imagenet\"):\n",
        "    !mkdir -p datasets/imagenet\n",
        "\n",
        "files = {\n",
        "    \"clip_train.tar.gz\": \"142xxRoMaHxX3BIfCw_1b_G_dgu-02Yq3\",\n",
        "    \"cc3m_subset_100k.tar.gz\": \"142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT\",\n",
        "    \"mscoco_val.tar.gz\": \"142tMsnclHTTPpnTXHSeNgTUlBk4She6o\",\n",
        "    \"val.tar\": \"1NXhfhwFy-nhdABACkodgYqm9pomDKE39\"\n",
        "}\n",
        "\n",
        "for fname, fid in files.items():\n",
        "    if not os.path.exists(fname):\n",
        "        !gdown {fid}\n",
        "\n",
        "if not os.path.exists(\"clip_train\"):\n",
        "    !tar xf clip_train.tar.gz\n",
        "\n",
        "if not os.path.exists(\"datasets/cc3m_subset_100k\"):\n",
        "    !tar xf cc3m_subset_100k.tar.gz -C datasets\n",
        "\n",
        "if not os.path.exists(\"datasets/ms_coco_val\"):\n",
        "    !tar xf mscoco_val.tar.gz -C datasets\n",
        "\n",
        "if not os.path.exists(\"datasets/imagenet/val\"):\n",
        "    !tar xf val.tar -C datasets/imagenet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEizVD8Gkf0O",
        "outputId": "74dec03f-55f1-4b2d-ed6e-24d13304a9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iSogCLR'...\n",
            "remote: Enumerating objects: 314, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 314 (delta 17), reused 13 (delta 13), pack-reused 289 (from 2)\u001b[K\n",
            "Receiving objects: 100% (314/314), 152.51 KiB | 5.08 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=142xxRoMaHxX3BIfCw_1b_G_dgu-02Yq3\n",
            "To: /content/drive/MyDrive/csce633/project/clip_train.tar.gz\n",
            "100% 4.06M/4.06M [00:00<00:00, 231MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT\n",
            "From (redirected): https://drive.google.com/uc?id=142zQjlOw0Xw4tKzXMrQjYE6NtGRTeasT&confirm=t&uuid=ce6340c1-630c-4580-be5c-8da86af2533e\n",
            "To: /content/drive/MyDrive/csce633/project/cc3m_subset_100k.tar.gz\n",
            "100% 3.07G/3.07G [00:14<00:00, 218MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=142tMsnclHTTPpnTXHSeNgTUlBk4She6o\n",
            "From (redirected): https://drive.google.com/uc?id=142tMsnclHTTPpnTXHSeNgTUlBk4She6o&confirm=t&uuid=0ce11241-908a-4926-b5b0-fc0e4bf28717\n",
            "To: /content/drive/MyDrive/csce633/project/mscoco_val.tar.gz\n",
            "100% 819M/819M [00:05<00:00, 147MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1NXhfhwFy-nhdABACkodgYqm9pomDKE39\n",
            "From (redirected): https://drive.google.com/uc?id=1NXhfhwFy-nhdABACkodgYqm9pomDKE39&confirm=t&uuid=627c3a4e-ca39-4da5-aafa-8d3df88698b4\n",
            "To: /content/drive/MyDrive/csce633/project/val.tar\n",
            "100% 6.75G/6.75G [00:54<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:./iSogCLR/bimodal_exps\n",
        "%env HUGGINGFACE_HUB_CACHE=./checkpoints/huggingface\n",
        "\n",
        "!pip install -r ./iSogCLR/requirements_colab.txt"
      ],
      "metadata": {
        "id": "RprrU6qTkxvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLIP Training"
      ],
      "metadata": {
        "id": "SGqGYErWd6q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "ita_type = \"clip\"\n",
        "\n",
        "optimizer_type = \"adamw\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"adam\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"momentum\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eBWCsnpypU16",
        "outputId": "41fb11e4-3799-435f-8a99-562200c79486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 20:51:26.306765: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-11 20:51:26.324855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762894286.346052   14017 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762894286.352494   14017 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762894286.369324   14017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762894286.369351   14017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762894286.369355   14017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762894286.369357   14017 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 20:51:26.374389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Creating retrieval dataset\n",
            "len of train_dataset: 100000\n",
            "len of coco val: 5000\n",
            "Creating model\n",
            "Start training\n",
            "Train Epoch: [0]  [  0/781]  eta: 3:36:09  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 10.2233  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 16.6066  data: 1.5860  max mem: 8390\n",
            "Train Epoch: [0]  [ 50/781]  eta: 0:10:04  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 7.0151  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.6016  data: 0.4603  max mem: 9085\n",
            "Train Epoch: [0]  [100/781]  eta: 0:08:03  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 5.6295  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5851  data: 0.4419  max mem: 9085\n",
            "Train Epoch: [0]  [150/781]  eta: 0:07:04  lr: 0.000048  lr_temp_net: 0.00000480  loss_ita: 3.7553  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5923  data: 0.4501  max mem: 9085\n",
            "Train Epoch: [0]  [200/781]  eta: 0:06:17  lr: 0.000048  lr_temp_net: 0.00000480  loss_ita: 3.3463  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5816  data: 0.4366  max mem: 9085\n",
            "Train Epoch: [0]  [250/781]  eta: 0:05:38  lr: 0.000086  lr_temp_net: 0.00000860  loss_ita: 2.6690  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5922  data: 0.4496  max mem: 9085\n",
            "Train Epoch: [0]  [300/781]  eta: 0:05:03  lr: 0.000086  lr_temp_net: 0.00000860  loss_ita: 2.7494  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.6057  data: 0.4632  max mem: 9085\n",
            "Train Epoch: [0]  [350/781]  eta: 0:04:30  lr: 0.000124  lr_temp_net: 0.00001240  loss_ita: 2.5145  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5920  data: 0.4490  max mem: 9085\n",
            "Train Epoch: [0]  [400/781]  eta: 0:03:57  lr: 0.000124  lr_temp_net: 0.00001240  loss_ita: 2.3854  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.6215  data: 0.4789  max mem: 9085\n",
            "Train Epoch: [0]  [450/781]  eta: 0:03:24  lr: 0.000162  lr_temp_net: 0.00001620  loss_ita: 2.3269  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5848  data: 0.4430  max mem: 9085\n",
            "Train Epoch: [0]  [500/781]  eta: 0:02:53  lr: 0.000162  lr_temp_net: 0.00001620  loss_ita: 2.3731  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5921  data: 0.4500  max mem: 9085\n",
            "Train Epoch: [0]  [550/781]  eta: 0:02:21  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 2.2821  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5996  data: 0.4573  max mem: 9085\n",
            "Train Epoch: [0]  [600/781]  eta: 0:01:50  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 2.0371  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5752  data: 0.4322  max mem: 9085\n",
            "Train Epoch: [0]  [650/781]  eta: 0:01:19  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 2.0237  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5938  data: 0.4513  max mem: 9085\n",
            "Train Epoch: [0]  [700/781]  eta: 0:00:49  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 1.6471  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5908  data: 0.4497  max mem: 9085\n",
            "Train Epoch: [0]  [750/781]  eta: 0:00:18  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 1.7440  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5884  data: 0.4453  max mem: 9085\n",
            "Train Epoch: [0]  [780/781]  eta: 0:00:00  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 1.8624  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5915  data: 0.4502  max mem: 9085\n",
            "Train Epoch: [0] Total time: 0:07:54 (0.6072 s / it)\n",
            "Averaged stats: lr: 0.0001  lr_temp_net: 0.0000  loss_ita: 3.1374  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [1]  [  0/781]  eta: 0:20:05  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.7059  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.5437  data: 1.3814  max mem: 9094\n",
            "Train Epoch: [1]  [ 50/781]  eta: 0:07:27  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.7937  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5857  data: 0.4430  max mem: 9094\n",
            "Train Epoch: [1]  [100/781]  eta: 0:06:51  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.5324  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5996  data: 0.4585  max mem: 9094\n",
            "Train Epoch: [1]  [150/781]  eta: 0:06:18  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.4709  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5970  data: 0.4547  max mem: 9094\n",
            "Train Epoch: [1]  [200/781]  eta: 0:05:47  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.2940  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5949  data: 0.4522  max mem: 9094\n",
            "Train Epoch: [1]  [250/781]  eta: 0:05:16  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.3689  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5757  data: 0.4330  max mem: 9094\n",
            "Train Epoch: [1]  [300/781]  eta: 0:04:46  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.4951  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5895  data: 0.4482  max mem: 9094\n",
            "Train Epoch: [1]  [350/781]  eta: 0:04:15  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.2009  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5863  data: 0.4442  max mem: 9094\n",
            "Train Epoch: [1]  [400/781]  eta: 0:03:45  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.2629  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5732  data: 0.4303  max mem: 9094\n",
            "Train Epoch: [1]  [450/781]  eta: 0:03:15  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.4219  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5940  data: 0.4505  max mem: 9094\n",
            "Train Epoch: [1]  [500/781]  eta: 0:02:45  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.3594  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5814  data: 0.4391  max mem: 9094\n",
            "Train Epoch: [1]  [550/781]  eta: 0:02:16  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.3985  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5902  data: 0.4473  max mem: 9094\n",
            "Train Epoch: [1]  [600/781]  eta: 0:01:46  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.3564  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5796  data: 0.4372  max mem: 9094\n",
            "Train Epoch: [1]  [650/781]  eta: 0:01:17  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.2643  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5878  data: 0.4439  max mem: 9094\n",
            "Train Epoch: [1]  [700/781]  eta: 0:00:47  lr: 0.000101  lr_temp_net: 0.00001005  loss_ita: 1.1898  avg_image_tau: 0.0100  avg_text_tau: 0.0100  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.5966  data: 0.4531  max mem: 9094\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1492, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1444, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1285, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 359, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 710, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 502, in main\n",
            "    train_stats = train(model, train_loader, optimizer, tokenizer, epoch, max_epoch, warmup_steps, device, lr_scheduler, \n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 67, in train\n",
            "    for i,(image, text, idx, text_idx) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/csce633/project/iSogCLR/bimodal_exps/utils.py\", line 137, in log_every\n",
            "    for obj in iterable:\n",
            "               ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 730, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/profiler.py\", line 793, in __exit__\n",
            "    torch.ops.profiler._record_function_exit._RecordFunction(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_ops.py\", line 1056, in __call__\n",
            "    def __call__(self, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n",
            "\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\", line 1, in <module>\n",
            "    from ._register_onnx_ops import _register_custom_op\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/ops/_register_onnx_ops.py\", line 5, in <module>\n",
            "    from torch.onnx import symbolic_opset11 as opset11\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/onnx/__init__.py\", line 65, in <module>\n",
            "    from .utils import (\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/onnx/utils.py\", line 24, in <module>\n",
            "    from torch.onnx import _constants, errors, symbolic_helper  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/onnx/symbolic_helper.py\", line 20, in <module>\n",
            "    from torch.onnx._internal import jit_utils\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/jit_utils.py\", line 26, in <module>\n",
            "    class GraphContext:\n",
            "  File \"/usr/lib/python3.12/dataclasses.py\", line 349, in __set_name__\n",
            "    def __set_name__(self, owner, name):\n",
            "\n",
            "KeyboardInterrupt\n",
            "Error calling __set_name__ on 'Field' instance 'new_nodes' in 'GraphContext'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 20, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\", line 9, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"<frozen importlib._bootstrap>\", line 1357, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 421, in __exit__\n",
            "  File \"<frozen importlib._bootstrap>\", line 378, in release\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "2025-11-11 21:06:50.679110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-11 21:06:50.698120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762895210.720378   17936 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762895210.726914   17936 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762895210.744034   17936 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762895210.744068   17936 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762895210.744071   17936 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762895210.744074   17936 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 21:06:50.749086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Creating retrieval dataset\n",
            "len of train_dataset: 100000\n",
            "len of coco val: 5000\n",
            "Creating model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 710, in <module>\n",
            "    main(args)\n",
            "  File \"/content/drive/MyDrive/csce633/project/./iSogCLR/bimodal_exps/clip.py\", line 478, in main\n",
            "    optimizer = create_optimizer(args, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/csce633/project/iSogCLR/bimodal_exps/optim/optim_factory.py\", line 77, in create_optimizer\n",
            "    optimizer = optim.SGD(parameters, momentum=args.momentum, nesterov=False, **opt_args)\n",
            "                                               ^^^^^^^^^^^^^\n",
            "AttributeError: 'Namespace' object has no attribute 'momentum'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SogCLR Training\n",
        "\n",
        "The following command runs the training script to train a ResNet50 (pretrained on ImageNet) and a DistilBERT (pretrained on BookCorpus and English Wikipedia) on the cc3m dataset using the SogCLR loss for 30 epochs with temperature 0.01."
      ],
      "metadata": {
        "id": "11x28L3vV2od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "ita_type = \"sogclr\"\n",
        "\n",
        "optimizer_type = \"adamw\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"adam\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"momentum\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n"
      ],
      "metadata": {
        "id": "I4BjOwHiWP2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fec7e0ce-b5c4-4f61-eb78-2902b120b7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 18:26:40.421211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762885600.441278   16299 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762885600.447374   16299 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762885600.463685   16299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762885600.463708   16299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762885600.463711   16299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762885600.463713   16299 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 18:26:40.468611: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Creating retrieval dataset\n",
            "len of train_dataset: 100000\n",
            "len of coco val: 5000\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 336kB/s]\n",
            "config.json: 100% 483/483 [00:00<00:00, 3.89MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 556kB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 1.11MB/s]\n",
            "Creating model\n",
            "model.safetensors: 100% 102M/102M [00:02<00:00, 45.4MB/s]\n",
            "model.safetensors: 100% 268M/268M [00:00<00:00, 338MB/s]\n",
            "Start training\n",
            "Train Epoch: [0]  [  0/781]  eta: 3:59:42  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 0.1540  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 18.4158  data: 1.1484  max mem: 8412\n",
            "Train Epoch: [0]  [ 50/781]  eta: 0:12:29  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 0.0834  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.6823  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [100/781]  eta: 0:09:47  lr: 0.000010  lr_temp_net: 0.00000100  loss_ita: 0.0586  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7018  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [150/781]  eta: 0:08:35  lr: 0.000048  lr_temp_net: 0.00000480  loss_ita: 0.0211  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7332  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [200/781]  eta: 0:07:39  lr: 0.000048  lr_temp_net: 0.00000480  loss_ita: 0.0138  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7077  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [250/781]  eta: 0:06:51  lr: 0.000086  lr_temp_net: 0.00000860  loss_ita: 0.0068  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7131  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [300/781]  eta: 0:06:07  lr: 0.000086  lr_temp_net: 0.00000860  loss_ita: 0.0107  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7112  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [350/781]  eta: 0:05:26  lr: 0.000124  lr_temp_net: 0.00001240  loss_ita: 0.0089  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7082  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [400/781]  eta: 0:04:45  lr: 0.000124  lr_temp_net: 0.00001240  loss_ita: 0.0083  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7109  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [450/781]  eta: 0:04:07  lr: 0.000162  lr_temp_net: 0.00001620  loss_ita: -0.0036  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7125  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [500/781]  eta: 0:03:28  lr: 0.000162  lr_temp_net: 0.00001620  loss_ita: 0.0139  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7119  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [550/781]  eta: 0:02:50  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 0.0039  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7116  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [600/781]  eta: 0:02:13  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 0.0027  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7108  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [650/781]  eta: 0:01:36  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: 0.0083  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7105  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [700/781]  eta: 0:00:59  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: -0.0081  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7103  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [750/781]  eta: 0:00:22  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: -0.0064  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7122  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [0]  [780/781]  eta: 0:00:00  lr: 0.000200  lr_temp_net: 0.00002000  loss_ita: -0.0065  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7128  data: 0.0006  max mem: 9108\n",
            "Train Epoch: [0] Total time: 0:09:31 (0.7316 s / it)\n",
            "Averaged stats: lr: 0.0001  lr_temp_net: 0.0000  loss_ita: 0.0165  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [1]  [  0/781]  eta: 0:20:57  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0299  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.6095  data: 0.9011  max mem: 9108\n",
            "Train Epoch: [1]  [ 50/781]  eta: 0:08:52  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0048  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7122  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [100/781]  eta: 0:08:10  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0020  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7121  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [150/781]  eta: 0:07:32  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0050  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7117  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [200/781]  eta: 0:06:55  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0017  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7103  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [250/781]  eta: 0:06:19  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0002  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7093  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [300/781]  eta: 0:05:43  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0068  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7100  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [350/781]  eta: 0:05:07  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0029  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7086  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [400/781]  eta: 0:04:31  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0004  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7099  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [450/781]  eta: 0:03:55  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7107  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [500/781]  eta: 0:03:20  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0020  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7113  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [550/781]  eta: 0:02:44  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0062  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7381  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [600/781]  eta: 0:02:09  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0141  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7116  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [650/781]  eta: 0:01:33  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0002  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7094  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [700/781]  eta: 0:00:57  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0004  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7114  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [750/781]  eta: 0:00:22  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: -0.0054  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7111  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [1]  [780/781]  eta: 0:00:00  lr: 0.000199  lr_temp_net: 0.00001995  loss_ita: 0.0101  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7104  data: 0.0004  max mem: 9108\n",
            "Train Epoch: [1] Total time: 0:09:16 (0.7129 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0023  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [2]  [  0/781]  eta: 0:21:12  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0047  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.6293  data: 0.9096  max mem: 9108\n",
            "Train Epoch: [2]  [ 50/781]  eta: 0:08:51  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7102  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [100/781]  eta: 0:08:09  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0014  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7113  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [150/781]  eta: 0:07:32  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0043  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7101  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [200/781]  eta: 0:06:55  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0020  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7112  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [250/781]  eta: 0:06:19  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0015  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7088  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [300/781]  eta: 0:05:42  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0007  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7093  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [350/781]  eta: 0:05:07  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7093  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [400/781]  eta: 0:04:31  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0107  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7093  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [450/781]  eta: 0:03:55  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0054  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7108  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [500/781]  eta: 0:03:20  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0031  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7120  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [550/781]  eta: 0:02:44  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0044  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7126  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [600/781]  eta: 0:02:08  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0070  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7139  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [650/781]  eta: 0:01:33  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0067  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7134  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [700/781]  eta: 0:00:57  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: -0.0000  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7111  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [750/781]  eta: 0:00:22  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0023  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7099  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [2]  [780/781]  eta: 0:00:00  lr: 0.000198  lr_temp_net: 0.00001978  loss_ita: 0.0057  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7105  data: 0.0004  max mem: 9108\n",
            "Train Epoch: [2] Total time: 0:09:16 (0.7119 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [3]  [  0/781]  eta: 0:22:15  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0007  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.7094  data: 0.9895  max mem: 9108\n",
            "Train Epoch: [3]  [ 50/781]  eta: 0:08:55  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0034  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7136  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [100/781]  eta: 0:08:12  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0028  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7139  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [150/781]  eta: 0:07:34  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0008  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7121  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [200/781]  eta: 0:06:56  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0064  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7103  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [250/781]  eta: 0:06:20  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0017  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7105  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [300/781]  eta: 0:05:44  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7107  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [350/781]  eta: 0:05:08  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0089  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7126  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [400/781]  eta: 0:04:32  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0049  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7126  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [450/781]  eta: 0:03:56  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0023  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7147  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [500/781]  eta: 0:03:20  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0007  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7120  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [550/781]  eta: 0:02:44  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0062  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7105  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [600/781]  eta: 0:02:09  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0023  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7107  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [650/781]  eta: 0:01:33  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0048  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7131  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [700/781]  eta: 0:00:57  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0011  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7117  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [750/781]  eta: 0:00:22  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: 0.0024  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7115  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [3]  [780/781]  eta: 0:00:00  lr: 0.000195  lr_temp_net: 0.00001951  loss_ita: -0.0030  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7127  data: 0.0005  max mem: 9108\n",
            "Train Epoch: [3] Total time: 0:09:17 (0.7135 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [4]  [  0/781]  eta: 0:20:40  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0091  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.5889  data: 0.8729  max mem: 9108\n",
            "Train Epoch: [4]  [ 50/781]  eta: 0:08:53  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0024  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7132  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [100/781]  eta: 0:08:11  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0053  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7127  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [150/781]  eta: 0:07:33  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7114  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [200/781]  eta: 0:06:56  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0035  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7091  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [250/781]  eta: 0:06:19  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0035  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7103  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [300/781]  eta: 0:05:43  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0034  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7107  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [350/781]  eta: 0:05:07  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0004  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7132  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [400/781]  eta: 0:04:32  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0047  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7124  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [450/781]  eta: 0:03:56  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0105  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7121  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [500/781]  eta: 0:03:20  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0005  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7108  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [550/781]  eta: 0:02:44  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0010  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7108  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [600/781]  eta: 0:02:09  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0022  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7094  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [650/781]  eta: 0:01:33  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7367  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [700/781]  eta: 0:00:57  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0021  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7114  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [750/781]  eta: 0:00:22  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: 0.0011  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7106  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [4]  [780/781]  eta: 0:00:00  lr: 0.000191  lr_temp_net: 0.00001914  loss_ita: -0.0085  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7109  data: 0.0004  max mem: 9108\n",
            "Train Epoch: [4] Total time: 0:09:17 (0.7133 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0012  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [5]  [  0/781]  eta: 0:20:19  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: -0.0120  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.5617  data: 0.8542  max mem: 9108\n",
            "Train Epoch: [5]  [ 50/781]  eta: 0:08:52  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7125  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [100/781]  eta: 0:08:11  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0016  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7130  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [150/781]  eta: 0:07:33  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0002  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7144  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [200/781]  eta: 0:06:57  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0097  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [250/781]  eta: 0:06:20  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: -0.0009  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7141  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [300/781]  eta: 0:05:44  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: -0.0047  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [350/781]  eta: 0:05:08  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0033  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [400/781]  eta: 0:04:32  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0032  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7137  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [450/781]  eta: 0:03:57  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0015  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7142  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [500/781]  eta: 0:03:21  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: -0.0012  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [550/781]  eta: 0:02:45  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: -0.0036  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7142  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [600/781]  eta: 0:02:09  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0020  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [650/781]  eta: 0:01:33  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7118  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [700/781]  eta: 0:00:57  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0035  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7118  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [750/781]  eta: 0:00:22  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0015  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7117  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [5]  [780/781]  eta: 0:00:00  lr: 0.000187  lr_temp_net: 0.00001867  loss_ita: 0.0064  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7121  data: 0.0004  max mem: 9108\n",
            "Train Epoch: [5] Total time: 0:09:18 (0.7150 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0010  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [6]  [  0/781]  eta: 0:21:24  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0046  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.6449  data: 0.9310  max mem: 9108\n",
            "Train Epoch: [6]  [ 50/781]  eta: 0:08:54  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0012  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7139  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [100/781]  eta: 0:08:12  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0028  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7153  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [150/781]  eta: 0:07:34  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0040  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7126  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [200/781]  eta: 0:06:57  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0005  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7129  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [250/781]  eta: 0:06:20  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0034  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7120  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [300/781]  eta: 0:05:44  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0035  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7122  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [350/781]  eta: 0:05:08  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0074  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7110  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [400/781]  eta: 0:04:32  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0061  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7122  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [450/781]  eta: 0:03:56  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0011  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7127  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [500/781]  eta: 0:03:20  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0022  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7136  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [550/781]  eta: 0:02:45  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0020  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7149  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [600/781]  eta: 0:02:09  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0092  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [650/781]  eta: 0:01:33  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7131  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [700/781]  eta: 0:00:57  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0039  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [750/781]  eta: 0:00:22  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7137  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [6]  [780/781]  eta: 0:00:00  lr: 0.000181  lr_temp_net: 0.00001810  loss_ita: -0.0003  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7148  data: 0.0005  max mem: 9108\n",
            "Train Epoch: [6] Total time: 0:09:17 (0.7145 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [7]  [  0/781]  eta: 0:20:35  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0116  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.5815  data: 0.8705  max mem: 9108\n",
            "Train Epoch: [7]  [ 50/781]  eta: 0:08:54  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0069  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7152  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [100/781]  eta: 0:08:12  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0018  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7151  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [150/781]  eta: 0:07:34  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7151  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [200/781]  eta: 0:06:58  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0116  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7155  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [250/781]  eta: 0:06:21  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7151  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [300/781]  eta: 0:05:45  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0024  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7138  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [350/781]  eta: 0:05:09  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0021  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [400/781]  eta: 0:04:33  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0057  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7137  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [450/781]  eta: 0:03:57  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0037  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [500/781]  eta: 0:03:21  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0027  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [550/781]  eta: 0:02:45  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0075  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [600/781]  eta: 0:02:09  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0007  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7143  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [650/781]  eta: 0:01:33  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0130  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7155  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [700/781]  eta: 0:00:57  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0008  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7158  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [750/781]  eta: 0:00:22  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: 0.0026  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7403  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [7]  [780/781]  eta: 0:00:00  lr: 0.000174  lr_temp_net: 0.00001744  loss_ita: -0.0028  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7132  data: 0.0005  max mem: 9108\n",
            "Train Epoch: [7] Total time: 0:09:19 (0.7165 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: 0.0001  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [8]  [  0/781]  eta: 0:20:20  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0046  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.5629  data: 0.8445  max mem: 9108\n",
            "Train Epoch: [8]  [ 50/781]  eta: 0:08:55  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0019  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7161  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [100/781]  eta: 0:08:13  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0138  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7160  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [150/781]  eta: 0:07:35  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0082  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7165  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [200/781]  eta: 0:06:58  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0037  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7147  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [250/781]  eta: 0:06:21  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7145  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [300/781]  eta: 0:05:45  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0021  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7165  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [350/781]  eta: 0:05:09  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0082  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7159  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [400/781]  eta: 0:04:33  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0001  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7163  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [450/781]  eta: 0:03:57  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0041  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7147  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [500/781]  eta: 0:03:21  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0019  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7152  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [550/781]  eta: 0:02:45  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0074  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7138  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [600/781]  eta: 0:02:09  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0028  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7135  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [650/781]  eta: 0:01:33  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0058  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7140  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [700/781]  eta: 0:00:58  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0041  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7157  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [750/781]  eta: 0:00:22  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: -0.0052  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [8]  [780/781]  eta: 0:00:00  lr: 0.000167  lr_temp_net: 0.00001671  loss_ita: 0.0015  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7159  data: 0.0005  max mem: 9108\n",
            "Train Epoch: [8] Total time: 0:09:19 (0.7164 s / it)\n",
            "Averaged stats: lr: 0.0002  lr_temp_net: 0.0000  loss_ita: -0.0004  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000\n",
            "Train Epoch: [9]  [  0/781]  eta: 0:21:21  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0043  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 1.6412  data: 0.9305  max mem: 9108\n",
            "Train Epoch: [9]  [ 50/781]  eta: 0:08:55  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0042  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7140  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [100/781]  eta: 0:08:13  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0094  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7155  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [150/781]  eta: 0:07:35  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0043  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7154  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [200/781]  eta: 0:06:58  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0005  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7150  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [250/781]  eta: 0:06:21  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0079  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7131  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [300/781]  eta: 0:05:45  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0044  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7140  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [350/781]  eta: 0:05:09  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0088  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7127  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [400/781]  eta: 0:04:33  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0007  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7152  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [450/781]  eta: 0:03:57  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0006  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7147  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [500/781]  eta: 0:03:21  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0032  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7144  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [550/781]  eta: 0:02:45  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0010  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7156  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [600/781]  eta: 0:02:09  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: 0.0001  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7156  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [650/781]  eta: 0:01:33  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0044  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7148  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [700/781]  eta: 0:00:58  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0045  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7151  data: 0.0002  max mem: 9108\n",
            "Train Epoch: [9]  [750/781]  eta: 0:00:22  lr: 0.000159  lr_temp_net: 0.00001590  loss_ita: -0.0013  avg_image_tau: 0.0000  avg_text_tau: 0.0000  cur_eta: 0.0000  grad_tau_image: 0.0000  grad_tau_text: 0.0000  b_I: 0.0000  b_T: 0.0000  v: 0.0000  lamda: 0.0000  weights_image_pos: 0.0000  weights_text_pos: 0.0000  time: 0.7134  data: 0.0002  max mem: 9108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## iSogCLR Training"
      ],
      "metadata": {
        "id": "O-SAOQkQf2E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "ita_type = \"isogclr_new_v2\"\n",
        "\n",
        "optimizer_type = \"adamw\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"adam\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n",
        "\n",
        "optimizer_type = \"momentum\"\n",
        "!CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "    --data_path ./datasets \\\n",
        "    --ann_path ./clip_train \\\n",
        "    --train_file cc3m_train_subset.json \\\n",
        "    --train_image_root cc3m_subset_100k \\\n",
        "    --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "    --init_model \\\n",
        "    --use_amp \\\n",
        "    --ita_type {ita_type} \\\n",
        "    --tau_init 0.01 \\\n",
        "    --sogclr_gamma 0.8 \\\n",
        "    --eta_init 0.03 --sched cosine \\\n",
        "    --no-distributed \\\n",
        "    --epochs {epochs} \\\n",
        "    --opt {optimizer_type}\n"
      ],
      "metadata": {
        "id": "XyFbXdlLf8vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "The following command runs the evaluation script to evaluate the retrieval performance of the trained model on the MSCOCO validation dataset and the zero-shot classification performance on the ImageNet validation dataset. The evaluation command is obtained by appending `--evaluate --checkpoint /path/to/your/checkpoint --zs_dataset imagenet --zs_datafolder /path/to/imagenet/val` to the training command."
      ],
      "metadata": {
        "id": "kmCh9QFuWx-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ita_type in [\"clip\", \"sogclr\", \"isogclr_new_v2\"]:\n",
        "    for optimizer_type in [\"adamw\", \"adam\", \"momentum\"]:\n",
        "        print(f\"=== Running {ita_type} with {optimizer_type} ===\")\n",
        "        !CUDA_VISIBLE_DEVICES=0 python ./iSogCLR/bimodal_exps/clip.py \\\n",
        "            --data_path ./datasets \\\n",
        "            --ann_path ./clip_train \\\n",
        "            --train_file cc3m_train_subset.json \\\n",
        "            --train_image_root cc3m_subset_100k \\\n",
        "            --output_dir {project_root}/output/{optimizer_type}/{ita_type}_cc3m_g0.8_e30 \\\n",
        "            --init_model \\\n",
        "            --use_amp \\\n",
        "            --ita_type {ita_type} \\\n",
        "            --tau_init 0.01 \\\n",
        "            --sogclr_gamma 0.8 \\\n",
        "            --eta_init 0.03 --sched cosine \\\n",
        "            --no-distributed \\\n",
        "            --epochs {epochs} \\\n",
        "            --opt {optimizer_type}"
      ],
      "metadata": {
        "id": "OdSq-cQwoork"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "ita_type = \"clip\"\n",
        "optimizers = [\"adamw\", \"adam\", \"momentum\"]\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "for opt in optimizers:\n",
        "    log_path = f\"{project_root}/output/{opt}/{ita_type}_cc3m_g0.8_e30/coco_log.txt\"\n",
        "    records = []\n",
        "    with open(log_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"best epoch\"):\n",
        "                continue\n",
        "            records.append(json.loads(line))\n",
        "    epochs = [r.get(\"epoch\", i) for i, r in enumerate(records)]\n",
        "    loss_ita = [float(r.get(\"train_loss_ita\", 0)) for r in records]\n",
        "    plt.plot(epochs, loss_ita, marker=\"o\", label=opt.upper())\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"train_loss_ita\")\n",
        "plt.title(f\"{ita_type.upper()} — Optimizer Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6Hj1UJrumshx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Benchmarks\n",
        "\n",
        "The following results are recall at 1 results on the provided MSCOCO and ImageNet datasets. The first row of results are from the model trained using the CLIP loss, and the second row of results are from the model trained using the SogCLR loss. All results are based on a batch size of 128 for 30-epoch pretraining. IR@1 denotes the recall at 1 of image retrieval on MSCOCO, TR@1 denotes the recall at 1 of text retrieval on MSCOCO, and ACC@1 denotes the top 1 accuracy on ImageNet. Average denotes the average of the three metrics.\n",
        "\n",
        "| Method | MSCOCO TR@1 | MSCOCO IR@1 | ImageNet ACC@1 | Average |\n",
        "|:----------:|:--------:|:--------:|:--------:|:--------:|\n",
        "| CLIP | 12.0 | 9.32 | 21.35 | 14.22 |\n",
        "| SogCLR |  14.38  |  10.73  | 24.54 | 16.55 |"
      ],
      "metadata": {
        "id": "B4tw47loXXPK"
      }
    }
  ]
}